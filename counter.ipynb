{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import math\n",
    "from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 3 handbags, 48.9ms\n",
      "Speed: 3.9ms preprocess, 48.9ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 2 handbags, 38.0ms\n",
      "Speed: 4.0ms preprocess, 38.0ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 1 backpack, 2 handbags, 1 cell phone, 38.6ms\n",
      "Speed: 4.1ms preprocess, 38.6ms inference, 3.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 backpack, 2 handbags, 1 cell phone, 38.7ms\n",
      "Speed: 4.0ms preprocess, 38.7ms inference, 4.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 1 backpack, 2 handbags, 1 cell phone, 38.5ms\n",
      "Speed: 4.0ms preprocess, 38.5ms inference, 4.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 1 handbag, 1 cell phone, 39.2ms\n",
      "Speed: 5.1ms preprocess, 39.2ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 train, 1 backpack, 2 handbags, 1 cell phone, 39.5ms\n",
      "Speed: 4.0ms preprocess, 39.5ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 1 boat, 2 backpacks, 1 handbag, 38.8ms\n",
      "Speed: 5.0ms preprocess, 38.8ms inference, 4.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 2 handbags, 37.8ms\n",
      "Speed: 5.1ms preprocess, 37.8ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 2 backpacks, 2 handbags, 40.1ms\n",
      "Speed: 3.2ms preprocess, 40.1ms inference, 3.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 1 backpack, 2 handbags, 39.8ms\n",
      "Speed: 7.0ms preprocess, 39.8ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 21 persons, 1 train, 1 backpack, 2 handbags, 1 cell phone, 40.1ms\n",
      "Speed: 6.0ms preprocess, 40.1ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 backpack, 2 handbags, 1 cell phone, 39.1ms\n",
      "Speed: 6.3ms preprocess, 39.1ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 3 backpacks, 2 handbags, 1 cell phone, 39.0ms\n",
      "Speed: 8.0ms preprocess, 39.0ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 2 backpacks, 39.1ms\n",
      "Speed: 6.4ms preprocess, 39.1ms inference, 3.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 3 backpacks, 1 handbag, 38.9ms\n",
      "Speed: 5.5ms preprocess, 38.9ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 2 backpacks, 1 handbag, 1 cell phone, 38.5ms\n",
      "Speed: 6.3ms preprocess, 38.5ms inference, 3.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 2 handbags, 39.8ms\n",
      "Speed: 4.0ms preprocess, 39.8ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 1 handbag, 1 cell phone, 38.9ms\n",
      "Speed: 7.9ms preprocess, 38.9ms inference, 3.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 2 backpacks, 1 handbag, 38.7ms\n",
      "Speed: 6.3ms preprocess, 38.7ms inference, 3.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 1 handbag, 1 cell phone, 38.5ms\n",
      "Speed: 7.1ms preprocess, 38.5ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 2 backpacks, 1 cell phone, 38.3ms\n",
      "Speed: 5.8ms preprocess, 38.3ms inference, 3.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 1 handbag, 1 cell phone, 39.2ms\n",
      "Speed: 4.0ms preprocess, 39.2ms inference, 4.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 train, 2 backpacks, 1 handbag, 38.3ms\n",
      "Speed: 5.6ms preprocess, 38.3ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 2 backpacks, 1 handbag, 1 suitcase, 39.9ms\n",
      "Speed: 6.9ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 2 handbags, 1 suitcase, 39.0ms\n",
      "Speed: 5.3ms preprocess, 39.0ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 3 handbags, 39.4ms\n",
      "Speed: 5.1ms preprocess, 39.4ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 13 persons, 1 train, 1 backpack, 2 handbags, 38.4ms\n",
      "Speed: 5.5ms preprocess, 38.4ms inference, 5.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 13 persons, 1 train, 3 backpacks, 2 handbags, 39.5ms\n",
      "Speed: 5.0ms preprocess, 39.5ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 2 handbags, 38.6ms\n",
      "Speed: 4.0ms preprocess, 38.6ms inference, 5.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 1 handbag, 38.7ms\n",
      "Speed: 5.5ms preprocess, 38.7ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 1 backpack, 1 handbag, 39.8ms\n",
      "Speed: 5.2ms preprocess, 39.8ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 2 backpacks, 39.6ms\n",
      "Speed: 4.5ms preprocess, 39.6ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 bus, 1 train, 1 backpack, 1 handbag, 1 suitcase, 40.1ms\n",
      "Speed: 6.0ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 1 backpack, 1 handbag, 38.7ms\n",
      "Speed: 5.5ms preprocess, 38.7ms inference, 3.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 backpack, 1 handbag, 40.3ms\n",
      "Speed: 7.4ms preprocess, 40.3ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 backpack, 2 handbags, 38.0ms\n",
      "Speed: 4.3ms preprocess, 38.0ms inference, 2.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 1 backpack, 2 handbags, 39.2ms\n",
      "Speed: 5.1ms preprocess, 39.2ms inference, 5.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 train, 1 backpack, 2 handbags, 37.8ms\n",
      "Speed: 5.0ms preprocess, 37.8ms inference, 4.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 train, 1 backpack, 1 handbag, 38.6ms\n",
      "Speed: 7.0ms preprocess, 38.6ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 backpack, 1 handbag, 39.9ms\n",
      "Speed: 7.9ms preprocess, 39.9ms inference, 3.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 2 backpacks, 1 handbag, 39.2ms\n",
      "Speed: 6.5ms preprocess, 39.2ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 1 handbag, 39.8ms\n",
      "Speed: 5.1ms preprocess, 39.8ms inference, 4.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 bus, 1 train, 1 backpack, 1 handbag, 39.7ms\n",
      "Speed: 8.0ms preprocess, 39.7ms inference, 3.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 1 backpack, 39.5ms\n",
      "Speed: 5.4ms preprocess, 39.5ms inference, 4.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 backpack, 1 handbag, 39.5ms\n",
      "Speed: 5.2ms preprocess, 39.5ms inference, 4.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 1 backpack, 1 handbag, 39.8ms\n",
      "Speed: 4.0ms preprocess, 39.8ms inference, 4.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 1 backpack, 1 handbag, 40.0ms\n",
      "Speed: 6.1ms preprocess, 40.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 1 backpack, 2 handbags, 38.9ms\n",
      "Speed: 4.5ms preprocess, 38.9ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 2 backpacks, 2 handbags, 38.1ms\n",
      "Speed: 8.0ms preprocess, 38.1ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 3 backpacks, 2 handbags, 39.1ms\n",
      "Speed: 6.4ms preprocess, 39.1ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 2 backpacks, 2 handbags, 39.6ms\n",
      "Speed: 6.5ms preprocess, 39.6ms inference, 3.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 2 backpacks, 1 handbag, 39.7ms\n",
      "Speed: 7.5ms preprocess, 39.7ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 2 backpacks, 3 handbags, 39.4ms\n",
      "Speed: 4.3ms preprocess, 39.4ms inference, 4.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 1 backpack, 3 handbags, 38.6ms\n",
      "Speed: 4.1ms preprocess, 38.6ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 3 handbags, 39.2ms\n",
      "Speed: 4.9ms preprocess, 39.2ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 bus, 1 train, 1 backpack, 3 handbags, 39.1ms\n",
      "Speed: 4.1ms preprocess, 39.1ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 bus, 1 train, 2 backpacks, 2 handbags, 39.1ms\n",
      "Speed: 4.0ms preprocess, 39.1ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 1 handbag, 38.7ms\n",
      "Speed: 5.1ms preprocess, 38.7ms inference, 2.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 bus, 1 train, 2 backpacks, 1 handbag, 39.1ms\n",
      "Speed: 5.3ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 bus, 1 train, 1 backpack, 1 handbag, 39.9ms\n",
      "Speed: 3.6ms preprocess, 39.9ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 14 persons, 1 bus, 1 train, 1 backpack, 1 handbag, 38.7ms\n",
      "Speed: 4.5ms preprocess, 38.7ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 1 backpack, 2 handbags, 38.1ms\n",
      "Speed: 4.1ms preprocess, 38.1ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 1 backpack, 1 handbag, 1 suitcase, 39.3ms\n",
      "Speed: 3.6ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 backpack, 1 handbag, 39.6ms\n",
      "Speed: 4.5ms preprocess, 39.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 1 backpack, 39.1ms\n",
      "Speed: 3.4ms preprocess, 39.1ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 train, 1 boat, 1 backpack, 39.2ms\n",
      "Speed: 3.9ms preprocess, 39.2ms inference, 4.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 2 backpacks, 1 handbag, 38.4ms\n",
      "Speed: 4.6ms preprocess, 38.4ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 train, 2 backpacks, 39.9ms\n",
      "Speed: 3.6ms preprocess, 39.9ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 21 persons, 2 backpacks, 39.7ms\n",
      "Speed: 4.0ms preprocess, 39.7ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 2 backpacks, 39.6ms\n",
      "Speed: 4.0ms preprocess, 39.6ms inference, 2.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 backpack, 1 handbag, 38.9ms\n",
      "Speed: 3.9ms preprocess, 38.9ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 backpack, 1 handbag, 38.8ms\n",
      "Speed: 4.5ms preprocess, 38.8ms inference, 4.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 bus, 1 backpack, 38.9ms\n",
      "Speed: 3.1ms preprocess, 38.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 2 backpacks, 39.1ms\n",
      "Speed: 4.1ms preprocess, 39.1ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 bus, 1 backpack, 1 handbag, 39.5ms\n",
      "Speed: 4.4ms preprocess, 39.5ms inference, 3.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 22 persons, 1 dog, 1 backpack, 1 handbag, 40.2ms\n",
      "Speed: 3.2ms preprocess, 40.2ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 handbag, 38.0ms\n",
      "Speed: 4.7ms preprocess, 38.0ms inference, 4.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 38.6ms\n",
      "Speed: 4.3ms preprocess, 38.6ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 bus, 2 backpacks, 1 handbag, 39.5ms\n",
      "Speed: 3.0ms preprocess, 39.5ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 14 persons, 1 train, 2 backpacks, 1 handbag, 39.5ms\n",
      "Speed: 4.0ms preprocess, 39.5ms inference, 4.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 2 backpacks, 1 handbag, 40.5ms\n",
      "Speed: 4.5ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 bus, 3 backpacks, 1 handbag, 39.0ms\n",
      "Speed: 4.8ms preprocess, 39.0ms inference, 5.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 bus, 2 backpacks, 1 handbag, 39.7ms\n",
      "Speed: 4.5ms preprocess, 39.7ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 bus, 2 backpacks, 1 handbag, 39.1ms\n",
      "Speed: 5.4ms preprocess, 39.1ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 2 backpacks, 1 handbag, 39.1ms\n",
      "Speed: 5.0ms preprocess, 39.1ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 1 handbag, 39.1ms\n",
      "Speed: 4.0ms preprocess, 39.1ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 backpack, 2 handbags, 38.6ms\n",
      "Speed: 4.0ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 2 backpacks, 38.3ms\n",
      "Speed: 4.0ms preprocess, 38.3ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 2 backpacks, 1 handbag, 38.2ms\n",
      "Speed: 4.0ms preprocess, 38.2ms inference, 3.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 2 backpacks, 2 handbags, 39.9ms\n",
      "Speed: 5.2ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 1 handbag, 38.6ms\n",
      "Speed: 5.0ms preprocess, 38.6ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 3 backpacks, 1 handbag, 39.4ms\n",
      "Speed: 4.4ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 1 handbag, 38.8ms\n",
      "Speed: 4.5ms preprocess, 38.8ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 2 backpacks, 1 handbag, 39.5ms\n",
      "Speed: 4.3ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 2 backpacks, 2 handbags, 39.2ms\n",
      "Speed: 3.0ms preprocess, 39.2ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 2 handbags, 38.8ms\n",
      "Speed: 4.9ms preprocess, 38.8ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 boat, 1 backpack, 1 handbag, 38.5ms\n",
      "Speed: 4.6ms preprocess, 38.5ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 backpack, 2 handbags, 39.3ms\n",
      "Speed: 4.1ms preprocess, 39.3ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 2 backpacks, 2 handbags, 39.4ms\n",
      "Speed: 4.0ms preprocess, 39.4ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 2 backpacks, 3 handbags, 38.2ms\n",
      "Speed: 4.9ms preprocess, 38.2ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 2 backpacks, 2 handbags, 39.8ms\n",
      "Speed: 3.9ms preprocess, 39.8ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 boat, 2 backpacks, 3 handbags, 38.8ms\n",
      "Speed: 4.7ms preprocess, 38.8ms inference, 2.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 boat, 1 backpack, 1 handbag, 39.0ms\n",
      "Speed: 4.9ms preprocess, 39.0ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 train, 1 backpack, 1 handbag, 38.7ms\n",
      "Speed: 4.0ms preprocess, 38.7ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 2 backpacks, 39.3ms\n",
      "Speed: 4.0ms preprocess, 39.3ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 2 backpacks, 39.7ms\n",
      "Speed: 4.4ms preprocess, 39.7ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 3 backpacks, 39.5ms\n",
      "Speed: 3.7ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 3 backpacks, 39.3ms\n",
      "Speed: 4.0ms preprocess, 39.3ms inference, 2.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 3 backpacks, 1 handbag, 39.1ms\n",
      "Speed: 4.9ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 14 persons, 1 train, 3 backpacks, 1 handbag, 39.8ms\n",
      "Speed: 4.0ms preprocess, 39.8ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 3 backpacks, 39.5ms\n",
      "Speed: 4.1ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 14 persons, 1 train, 2 backpacks, 1 handbag, 39.8ms\n",
      "Speed: 4.0ms preprocess, 39.8ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 3 backpacks, 39.1ms\n",
      "Speed: 4.1ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 3 backpacks, 38.7ms\n",
      "Speed: 5.0ms preprocess, 38.7ms inference, 3.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 1 backpack, 2 handbags, 39.0ms\n",
      "Speed: 5.1ms preprocess, 39.0ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 2 backpacks, 2 handbags, 1 skateboard, 39.9ms\n",
      "Speed: 4.1ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 2 backpacks, 1 handbag, 1 suitcase, 1 skateboard, 38.7ms\n",
      "Speed: 3.9ms preprocess, 38.7ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 2 backpacks, 38.4ms\n",
      "Speed: 3.9ms preprocess, 38.4ms inference, 5.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 2 backpacks, 1 handbag, 39.5ms\n",
      "Speed: 4.0ms preprocess, 39.5ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 14 persons, 1 train, 2 backpacks, 1 handbag, 1 skateboard, 38.7ms\n",
      "Speed: 4.0ms preprocess, 38.7ms inference, 3.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 backpack, 1 handbag, 40.4ms\n",
      "Speed: 4.1ms preprocess, 40.4ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 1 handbag, 39.0ms\n",
      "Speed: 4.5ms preprocess, 39.0ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 3 backpacks, 39.5ms\n",
      "Speed: 4.8ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 2 backpacks, 1 handbag, 39.4ms\n",
      "Speed: 3.9ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 1 boat, 3 backpacks, 39.6ms\n",
      "Speed: 3.9ms preprocess, 39.6ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 1 boat, 2 backpacks, 39.6ms\n",
      "Speed: 3.8ms preprocess, 39.6ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 16 persons, 1 train, 1 boat, 3 backpacks, 39.1ms\n",
      "Speed: 3.9ms preprocess, 39.1ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 3 backpacks, 38.3ms\n",
      "Speed: 5.0ms preprocess, 38.3ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 bus, 1 train, 3 backpacks, 1 handbag, 39.5ms\n",
      "Speed: 4.0ms preprocess, 39.5ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 2 backpacks, 1 handbag, 38.0ms\n",
      "Speed: 3.9ms preprocess, 38.0ms inference, 4.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 5 backpacks, 39.8ms\n",
      "Speed: 3.3ms preprocess, 39.8ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 4 backpacks, 39.4ms\n",
      "Speed: 4.1ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 3 backpacks, 39.4ms\n",
      "Speed: 4.5ms preprocess, 39.4ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 3 backpacks, 38.7ms\n",
      "Speed: 3.9ms preprocess, 38.7ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 2 backpacks, 39.4ms\n",
      "Speed: 4.6ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 3 backpacks, 39.1ms\n",
      "Speed: 4.0ms preprocess, 39.1ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 3 backpacks, 38.9ms\n",
      "Speed: 3.9ms preprocess, 38.9ms inference, 4.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 3 backpacks, 39.1ms\n",
      "Speed: 4.5ms preprocess, 39.1ms inference, 4.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 19 persons, 1 train, 2 backpacks, 2 handbags, 39.0ms\n",
      "Speed: 4.5ms preprocess, 39.0ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 21 persons, 1 train, 1 backpack, 38.7ms\n",
      "Speed: 5.1ms preprocess, 38.7ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 train, 2 backpacks, 39.8ms\n",
      "Speed: 3.7ms preprocess, 39.8ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 18 persons, 1 train, 1 boat, 2 backpacks, 38.8ms\n",
      "Speed: 4.2ms preprocess, 38.8ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 20 persons, 1 train, 1 backpack, 1 handbag, 39.6ms\n",
      "Speed: 3.1ms preprocess, 39.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 1 backpack, 1 handbag, 39.3ms\n",
      "Speed: 4.8ms preprocess, 39.3ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 17 persons, 1 train, 2 backpacks, 2 handbags, 38.7ms\n",
      "Speed: 4.1ms preprocess, 38.7ms inference, 5.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 15 persons, 1 train, 3 backpacks, 1 handbag, 39.7ms\n",
      "Speed: 4.1ms preprocess, 39.7ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(r\"C:\\Users\\aashutosh kumar\\Downloads\\People.mp4\")\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "mask = cv2.imread(r\"C:\\Projects\\People-Counter\\Peo_Mask.png\")\n",
    "mask = cv2.resize(mask, (700, 600))\n",
    "tracker = Sort(max_age = 20,min_hits = 2,iou_threshold = 0.3)\n",
    "limits = [536,337,606,510]\n",
    "total_counts = []\n",
    "\n",
    "while(True):\n",
    "    r, frame = cap.read()\n",
    "\n",
    "    if r == True:\n",
    "        frame = cv2.resize(frame, (700, 600))\n",
    "        frame_rgn = cv2.bitwise_and(frame, mask) \n",
    "        \n",
    "        detections = np.empty((0,5))\n",
    "        results = model(frame_rgn, stream=True)\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                class_id = int(box.cls[0])\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "                class_Name = classNames[class_id]\n",
    "\n",
    "                if class_Name == \"person\" and confidence > 0.4:\n",
    "                    # cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0),2,4)  \n",
    "                    curr_array = np.array([x1, y1, x2, y2, confidence])\n",
    "                    detections = np.vstack((detections, curr_array))\n",
    "        \n",
    "        tracking_res = tracker.update(detections)\n",
    "        \n",
    "        cv2.line(frame, (limits[0], limits[1]), (limits[2], limits[3]), (255,0,0),4)\n",
    "        for res in tracking_res:\n",
    "            x1, x2, y1, y2, id = res\n",
    "            x1, x2, y1, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (150, 200, 0), 3, 1)\n",
    "\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            cx = x1 + w // 2\n",
    "            cy = y1 + h // 2\n",
    "            \n",
    "            cv2.circle(frame, (cx,cy), 2, (0,0,255),3)\n",
    "            # cv2.line(frame, (limits[0], limits[1]), (limits[2], limits[3]), (255,0,0))\n",
    "            if limits[0] < cx < limits[2] and limits[1] - 90 < cy < limits[1] + 90:\n",
    "                if id not in total_counts:\n",
    "                    total_counts.append(id)\n",
    "                    cv2.line(frame, (limits[0], limits[1]), (limits[2], limits[3]), (0, 255, 0), 5)\n",
    "            \n",
    "            cv2.putText(frame,str(len(total_counts)),(25,70),cv2.FONT_HERSHEY_PLAIN,5,(15,241,249),8)\n",
    "\n",
    "\n",
    "        cv2.imshow(\"LIVE\", frame)\n",
    "        # cv2.imshow(\"Mask\", frame_rgn)\n",
    "        if cv2.waitKey(25) & 0xff == ord(\"p\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
